# 크롤링 기초
## 데이터 수집 사전 지식
### 크롤링 vs 스크랩핑
- 크롤링 : 방대한 범위에서 규칙적으로 데이터를 수집
  - 주기적, 대용량
- 스크랩핑 : 웹 사이트 값을 가져오지만 정확하게. 비교적 적은 값으로. 
- 자동화를 시켜놓으면 주기적으로 어떤 값을 가져올 수 있음.
- 크롤링, 스크랩핑 용어 상관 없이 사용해도 무관.

### HTML Tag
- 타겟 데이터를 가져옴
- 태그 규칙으로

### 크롬 개발자 도구
- 크롤링 하려면 필수!! 제대로 알아야 함.
- Elements Tab : CSS Selector
- Network Tab : Http 처리 과정
- 단축키 : Ctrl + Shift + i   
![.img](/.img/chrome_dev_crawl.PNG)
- 이 빨간 원 아이콘 클릭해서 수집 원하는 데이터 블록 선택하고 Copy함.


# 크롤링 주의사항

## 사전 기초지식
- 대상 웹 페이지 조건 확인 - robots.txt
    - 크롤링을 허용하는지.
- 크롤러 분류 - 상태 유무, Javascript 유무
    - 내가 볼 정보가 반드시 로그인을 해야 하는지.
    - Javascript를 사용해서 보여주는 정보는 Selenium 사용해야 함.
- Request 요청 주의 할 점 - 서버 부하 고려
    - 다른 사용자가 피해를 입으면 안됨.
        - 막힐 수 있음. 상대 사이트에 대한 예의를 지켜야 함.
    - api를 활용하면 서버에 부하를 주지도 않음.
    - 되도록 api를 활용.
- 콘텐츠 저작권 문제
    - 이미지 크롤링을 하게 되면 저작권 라이센스 확인해야 함.
- 페이지 구조 변경 가능성 숙지
    - 사이트는 잘 바뀌니까 그때그때 바뀌는거에 대처해야 함.

## robots.txt

```
User-agent: *
Disallow: /
```

- 모든 로봇들에 대해 "/"접근을 차단한다.
- 웹에서 "/"이걸 루트 혹은 최상위 디렉토리라 함. 로봇이 사이트의 어떤 페에지에도 접근 할 수 없게 작성한 내용

```
User-agent: *
Allow: /
```
- 모든 로봇들에 대해 모든 페이지에 접근 가능함
- Disallow와 Allow 구문 적절히 잘 사용해야 함.

```
User-agent: *
Disallow: /cgi-bin/
Disallow: /tmp/
Disallow: /junk/
```

- 원칙적으로는 다 허용하지만, 저 세 개(/cgi-bin/ ,/tmp/, /junk/)는 허용 안한다.

```
User-agent: BadBot
Disallow: /
```

- 특정 봇(여기선 BadBot)에 대해서는 접근을 허락하지 않는다.

```
User-agent: googlebot # googlebot 로봇만 허용
Disallow: /private/ # 이 디렉토리를 접근 차단한다.
```

이와 같이 사이트마다 접근 범위 지정함.